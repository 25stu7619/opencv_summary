# Image Classification vs Regression ì™„ë²½ ë¹„êµ

## ğŸ“‹ ëª©ì°¨
1. [í•µì‹¬ ì°¨ì´ì  ìš”ì•½](#í•µì‹¬-ì°¨ì´ì -ìš”ì•½)
2. [Image Classification ìƒì„¸](#image-classification-ìƒì„¸)
3. [Regression ìƒì„¸](#regression-ìƒì„¸)
4. [ë¹„êµí‘œ](#ë¹„êµí‘œ)
5. [ì‹¤ì „ ì˜ˆì œ ì½”ë“œ](#ì‹¤ì „-ì˜ˆì œ-ì½”ë“œ)
6. [ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ](#ì–¸ì œ-ë¬´ì—‡ì„-ì‚¬ìš©í• ê¹Œ)

---

## í•µì‹¬ ì°¨ì´ì  ìš”ì•½

### ğŸ¯ í•œ ë¬¸ì¥ ì •ë¦¬

```
Classification: "ì´ê²ƒì€ ë¬´ì—‡ì¸ê°€?" (ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜)
Regression:     "ì´ê²ƒì€ ì–¼ë§ˆì¸ê°€?" (ìˆ˜ì¹˜ ì˜ˆì¸¡)
```

### ğŸ“Š ì‹œê°ì  ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Image Classification                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ì…ë ¥: ì‚¬ì§„ ğŸ–¼ï¸                                          â”‚
â”‚         â†“                                               â”‚
â”‚  ì¶œë ¥: [ê°œ, ê³ ì–‘ì´, ìƒˆ] ì¤‘ í•˜ë‚˜                          â”‚
â”‚                                                         â”‚
â”‚  ì˜ˆì‹œ:                                                  â”‚
â”‚  ğŸ• ì‚¬ì§„ â†’ "ê°œ" (ì¹´í…Œê³ ë¦¬)                              â”‚
â”‚  ğŸ± ì‚¬ì§„ â†’ "ê³ ì–‘ì´" (ì¹´í…Œê³ ë¦¬)                          â”‚
â”‚  ğŸ¦ ì‚¬ì§„ â†’ "ìƒˆ" (ì¹´í…Œê³ ë¦¬)                              â”‚
â”‚                                                         â”‚
â”‚  ì¶œë ¥ í˜•íƒœ: ì´ì‚°ì  (Discrete)                           â”‚
â”‚  â””â”€ ì •í•´ì§„ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ                       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Regression                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ì…ë ¥: ì‚¬ì§„ ğŸ–¼ï¸                                          â”‚
â”‚         â†“                                               â”‚
â”‚  ì¶œë ¥: ì—°ì†ì ì¸ ìˆ«ì ê°’                                  â”‚
â”‚                                                         â”‚
â”‚  ì˜ˆì‹œ:                                                  â”‚
â”‚  ğŸ  ì§‘ ì‚¬ì§„ â†’ "3ì–µ 5ì²œë§Œì›" (ê°€ê²©)                      â”‚
â”‚  ğŸ‘¤ ì–¼êµ´ ì‚¬ì§„ â†’ "28.5ì„¸" (ë‚˜ì´)                         â”‚
â”‚  ğŸ“ ë¬¼ì²´ ì‚¬ì§„ â†’ "x=120.5, y=85.3" (ìœ„ì¹˜)                â”‚
â”‚                                                         â”‚
â”‚  ì¶œë ¥ í˜•íƒœ: ì—°ì†ì  (Continuous)                         â”‚
â”‚  â””â”€ ë¬´í•œíˆ ë§ì€ ê°€ëŠ¥í•œ ê°’                               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Image Classification ìƒì„¸

### ğŸ” ì •ì˜

**Image Classification**ì€ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ **ë¯¸ë¦¬ ì •ì˜ëœ ì¹´í…Œê³ ë¦¬(í´ë˜ìŠ¤)** ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

### ğŸ“ íŠ¹ì§•

```
1ï¸âƒ£ ì¶œë ¥: ì¹´í…Œê³ ë¦¬ (í´ë˜ìŠ¤ ë ˆì´ë¸”)
   - ê°œ, ê³ ì–‘ì´, ê°œ ì¤‘ í•˜ë‚˜
   - 0, 1, 2 ê°™ì€ ì •ìˆ˜
   - One-hot encoding: [1, 0, 0]

2ï¸âƒ£ ì¶œë ¥ ê°œìˆ˜: ê³ ì •ë¨
   - 3ê°œ í´ë˜ìŠ¤ â†’ 3ê°œ ì¶œë ¥ ë‰´ëŸ°
   - 1000ê°œ í´ë˜ìŠ¤ â†’ 1000ê°œ ì¶œë ¥ ë‰´ëŸ°

3ï¸âƒ£ í™œì„±í™” í•¨ìˆ˜: Softmax
   - í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜
   - í•©ì´ 1ì´ ë˜ë„ë¡

4ï¸âƒ£ ì†ì‹¤ í•¨ìˆ˜: Cross-Entropy
   - ë¶„ë¥˜ ì„±ëŠ¥ ì¸¡ì •
```

### ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°

```python
# Classification ëª¨ë¸ ì˜ˆì‹œ

ì…ë ¥ ì´ë¯¸ì§€ (224, 224, 3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CNN Backbone      â”‚
â”‚   (íŠ¹ì§• ì¶”ì¶œ)        â”‚
â”‚   - Conv layers     â”‚
â”‚   - Pooling         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flatten           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense(512)        â”‚
â”‚   ReLU              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense(3)          â”‚  â† í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼
â”‚   Softmax           â”‚  â† í™•ë¥ ë¡œ ë³€í™˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ì¶œë ¥: [0.8, 0.15, 0.05]
      ê°œ   ê³ ì–‘ì´  ìƒˆ
      
â†’ ì˜ˆì¸¡: "ê°œ" (ê°€ì¥ ë†’ì€ í™•ë¥ )
```

### ğŸ’» ì½”ë“œ ì˜ˆì‹œ

```python
import tensorflow as tf
from tensorflow.keras import layers, models

# Classification ëª¨ë¸
def build_classification_model(num_classes=3):
    model = models.Sequential([
        # CNN ë°±ë³¸
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # ë¶„ë¥˜ê¸°
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        
        # ì¶œë ¥ì¸µ
        layers.Dense(num_classes, activation='softmax')  # â† Softmax!
    ])
    
    # ì»´íŒŒì¼
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',  # â† Cross-Entropy!
        metrics=['accuracy']
    )
    
    return model

# ì‚¬ìš© ì˜ˆì‹œ
model = build_classification_model(num_classes=3)

# ì˜ˆì¸¡
predictions = model.predict(image)
# ì¶œë ¥: [[0.8, 0.15, 0.05]]
#        ê°œ   ê³ ì–‘ì´  ìƒˆ

predicted_class = np.argmax(predictions[0])
# ì¶œë ¥: 0 (ê°œ)
```

### ğŸ“Š ì¶œë ¥ í•´ì„

```python
# Classification ì¶œë ¥ ì˜ˆì‹œ
predictions = [0.8, 0.15, 0.05]

í•´ì„:
- ê°œì¼ í™•ë¥ : 80%
- ê³ ì–‘ì´ì¼ í™•ë¥ : 15%
- ìƒˆì¼ í™•ë¥ : 5%
- í•©ê³„: 100%

ìµœì¢… ì˜ˆì¸¡: "ê°œ" (ê°€ì¥ ë†’ì€ í™•ë¥ )
```

### ğŸ¯ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€

```
1. ë™ë¬¼ ë¶„ë¥˜
   ì…ë ¥: ë™ë¬¼ ì‚¬ì§„
   ì¶œë ¥: [ê°œ, ê³ ì–‘ì´, ìƒˆ, ë§, ì†Œ]

2. ì˜ë£Œ ì˜ìƒ ì§„ë‹¨
   ì…ë ¥: X-ray ì´ë¯¸ì§€
   ì¶œë ¥: [ì •ìƒ, íë ´, ê²°í•µ, ì•”]

3. ê°ì • ì¸ì‹
   ì…ë ¥: ì–¼êµ´ ì‚¬ì§„
   ì¶œë ¥: [í–‰ë³µ, ìŠ¬í””, í™”ë‚¨, ë†€ëŒ, ì¤‘ë¦½]

4. ì œí’ˆ ë¶„ë¥˜
   ì…ë ¥: ì œí’ˆ ì‚¬ì§„
   ì¶œë ¥: [ì˜ë¥˜, ì „ìì œí’ˆ, ì‹í’ˆ, ê°€êµ¬, ì±…]

5. í•„ê¸° ì¸ì‹
   ì…ë ¥: ì†ê¸€ì”¨ ì´ë¯¸ì§€
   ì¶œë ¥: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
```

---

## Regression ìƒì„¸

### ğŸ” ì •ì˜

**Regression**ì€ ì…ë ¥ ì´ë¯¸ì§€ë¡œë¶€í„° **ì—°ì†ì ì¸ ìˆ˜ì¹˜ ê°’**ì„ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

### ğŸ“ íŠ¹ì§•

```
1ï¸âƒ£ ì¶œë ¥: ì—°ì†ì ì¸ ì‹¤ìˆ˜ ê°’
   - ë‚˜ì´: 28.5ì„¸
   - ê°€ê²©: 3,500,000ì›
   - ì¢Œí‘œ: (x=120.5, y=85.3)

2ï¸âƒ£ ì¶œë ¥ ê°œìˆ˜: ì˜ˆì¸¡í•  ê°’ì˜ ê°œìˆ˜
   - 1ê°œ ê°’ â†’ 1ê°œ ì¶œë ¥ ë‰´ëŸ°
   - 10ê°œ ì¢Œí‘œ â†’ 10ê°œ ì¶œë ¥ ë‰´ëŸ°

3ï¸âƒ£ í™œì„±í™” í•¨ìˆ˜: Linear (ë˜ëŠ” ì—†ìŒ)
   - ì‹¤ìˆ˜ ë²”ìœ„ ì „ì²´ ì‚¬ìš©
   - ì œí•œ ì—†ìŒ

4ï¸âƒ£ ì†ì‹¤ í•¨ìˆ˜: MSE, MAE
   - ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´
```

### ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°

```python
# Regression ëª¨ë¸ ì˜ˆì‹œ

ì…ë ¥ ì´ë¯¸ì§€ (224, 224, 3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CNN Backbone      â”‚
â”‚   (íŠ¹ì§• ì¶”ì¶œ)        â”‚
â”‚   - Conv layers     â”‚
â”‚   - Pooling         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flatten           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense(512)        â”‚
â”‚   ReLU              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense(1)          â”‚  â† ì˜ˆì¸¡í•  ê°’ì˜ ê°œìˆ˜
â”‚   Linear            â”‚  â† í™œì„±í™” í•¨ìˆ˜ ì—†ìŒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ì¶œë ¥: [28.5]
      ë‚˜ì´(ì„¸)
      
â†’ ì˜ˆì¸¡: 28.5ì„¸
```

### ğŸ’» ì½”ë“œ ì˜ˆì‹œ

```python
import tensorflow as tf
from tensorflow.keras import layers, models

# Regression ëª¨ë¸
def build_regression_model(num_outputs=1):
    model = models.Sequential([
        # CNN ë°±ë³¸
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # íšŒê·€ê¸°
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.5),
        
        # ì¶œë ¥ì¸µ
        layers.Dense(num_outputs, activation='linear')  # â† Linear!
        # ë˜ëŠ” activation=None
    ])
    
    # ì»´íŒŒì¼
    model.compile(
        optimizer='adam',
        loss='mse',  # â† MSE (Mean Squared Error)!
        metrics=['mae']  # MAE (Mean Absolute Error)
    )
    
    return model

# ì‚¬ìš© ì˜ˆì‹œ
model = build_regression_model(num_outputs=1)

# ì˜ˆì¸¡
predictions = model.predict(image)
# ì¶œë ¥: [[28.5]]
#        ë‚˜ì´

predicted_age = predictions[0][0]
# ì¶œë ¥: 28.5
```

### ğŸ“Š ì¶œë ¥ í•´ì„

```python
# Regression ì¶œë ¥ ì˜ˆì‹œ

# 1) ë‹¨ì¼ ê°’ ì˜ˆì¸¡ (ë‚˜ì´)
prediction = [28.5]
í•´ì„: ì˜ˆì¸¡ ë‚˜ì´ = 28.5ì„¸

# 2) ë‹¤ì¤‘ ê°’ ì˜ˆì¸¡ (ì–¼êµ´ ëœë“œë§ˆí¬)
prediction = [120.5, 85.3, 200.1, 90.5, 160.7, 120.0]
             [x1,    y1,   x2,    y2,   x3,    y3]
í•´ì„: 
  - ì¢Œì¸¡ ëˆˆ ìœ„ì¹˜: (120.5, 85.3)
  - ìš°ì¸¡ ëˆˆ ìœ„ì¹˜: (200.1, 90.5)
  - ì½” ìœ„ì¹˜: (160.7, 120.0)

# 3) ì§‘ ê°€ê²© ì˜ˆì¸¡
prediction = [350000000]
í•´ì„: ì˜ˆì¸¡ ê°€ê²© = 3ì–µ 5ì²œë§Œì›
```

### ğŸ¯ ì‹¤ì œ ì‘ìš© ì‚¬ë¡€

```
1. ë‚˜ì´ ì˜ˆì¸¡
   ì…ë ¥: ì–¼êµ´ ì‚¬ì§„
   ì¶œë ¥: 28.5ì„¸

2. ì§‘ ê°€ê²© ì˜ˆì¸¡
   ì…ë ¥: ì§‘ ì‚¬ì§„
   ì¶œë ¥: 3ì–µ 5ì²œë§Œì›

3. ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
   ì…ë ¥: ì–¼êµ´ ì‚¬ì§„
   ì¶œë ¥: (x1, y1, x2, y2, ...) ì¢Œí‘œë“¤

4. ê¹Šì´ ì¶”ì •
   ì…ë ¥: ì¼ë°˜ ì‚¬ì§„
   ì¶œë ¥: ê° í”½ì…€ì˜ ê¹Šì´ ê°’

5. ìì„¸ ì¶”ì •
   ì…ë ¥: ì‚¬ëŒ ì‚¬ì§„
   ì¶œë ¥: ê´€ì ˆ ìœ„ì¹˜ ì¢Œí‘œë“¤

6. ê°ì²´ í¬ê¸° ì¸¡ì •
   ì…ë ¥: ë¬¼ì²´ ì‚¬ì§„
   ì¶œë ¥: ê¸¸ì´(cm), ë„“ì´(cmÂ²)
```

---

## ë¹„êµí‘œ

### ğŸ“‹ ìƒì„¸ ë¹„êµ

| í•­ëª© | Classification | Regression |
|------|----------------|------------|
| **ì¶œë ¥ íƒ€ì…** | ì¹´í…Œê³ ë¦¬ (ì´ì‚°ì ) | ìˆ«ì (ì—°ì†ì ) |
| **ì¶œë ¥ ì˜ˆì‹œ** | "ê°œ", "ê³ ì–‘ì´", "ìƒˆ" | 28.5, 120.3, [x, y] |
| **ì¶œë ¥ ë‰´ëŸ° ìˆ˜** | í´ë˜ìŠ¤ ê°œìˆ˜ (ì˜ˆ: 3ê°œ) | ì˜ˆì¸¡í•  ê°’ ê°œìˆ˜ (ì˜ˆ: 1ê°œ) |
| **í™œì„±í™” í•¨ìˆ˜** | **Softmax** | **Linear** (ë˜ëŠ” ì—†ìŒ) |
| **ì†ì‹¤ í•¨ìˆ˜** | **Cross-Entropy** | **MSE, MAE** |
| **í‰ê°€ ì§€í‘œ** | Accuracy, F1-Score | MSE, MAE, RÂ² |
| **ì¶œë ¥ ë²”ìœ„** | [0, 1] (í™•ë¥ ) | (-âˆ, +âˆ) (ì‹¤ìˆ˜) |
| **ì¶œë ¥ í•©** | 1.0 (100%) | ì œì•½ ì—†ìŒ |
| **ì˜ˆì¸¡ ë°©ë²•** | argmax (ìµœëŒ€ í™•ë¥ ) | ì§ì ‘ ì‚¬ìš© |

### ğŸ“Š ìˆ˜ì‹ ë¹„êµ

#### Classification

```
ì¶œë ¥ì¸µ:
y = Softmax(Wx + b)

Softmax:
y_i = exp(x_i) / Î£ exp(x_j)

ì†ì‹¤ í•¨ìˆ˜ (Cross-Entropy):
Loss = -Î£ y_true * log(y_pred)

ì˜ˆì‹œ:
ì‹¤ì œ: [1, 0, 0] (ê°œ)
ì˜ˆì¸¡: [0.8, 0.15, 0.05]
Loss = -(1*log(0.8) + 0*log(0.15) + 0*log(0.05))
     = -log(0.8)
     â‰ˆ 0.223
```

#### Regression

```
ì¶œë ¥ì¸µ:
y = Wx + b  (Linear)

ì†ì‹¤ í•¨ìˆ˜ (MSE):
Loss = (1/n) * Î£(y_true - y_pred)Â²

ì˜ˆì‹œ:
ì‹¤ì œ: 30.0ì„¸
ì˜ˆì¸¡: 28.5ì„¸
Loss = (30.0 - 28.5)Â²
     = 2.25
```

---

## ì‹¤ì „ ì˜ˆì œ ì½”ë“œ

### ğŸ”´ Classification ì „ì²´ ì˜ˆì œ

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

# 1. ë°ì´í„° ì¤€ë¹„ (CIFAR-10 ì˜ˆì‹œ)
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()

# ì •ê·œí™”
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# One-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

print("í•™ìŠµ ë°ì´í„°:", X_train.shape)  # (50000, 32, 32, 3)
print("í•™ìŠµ ë ˆì´ë¸”:", y_train.shape)  # (50000, 10)

# 2. Classification ëª¨ë¸ êµ¬ì¶•
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    
    # ì¶œë ¥ì¸µ: 10ê°œ í´ë˜ìŠ¤
    layers.Dense(10, activation='softmax')  # â† Softmax
])

# 3. ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',  # â† Cross-Entropy
    metrics=['accuracy']
)

# 4. í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=64,
    validation_data=(X_test, y_test)
)

# 5. ì˜ˆì¸¡
sample_image = X_test[0:1]
prediction = model.predict(sample_image)

print("\nì˜ˆì¸¡ ê²°ê³¼:")
print("í™•ë¥ :", prediction[0])
print("ì˜ˆì¸¡ í´ë˜ìŠ¤:", np.argmax(prediction[0]))
print("ì‹¤ì œ í´ë˜ìŠ¤:", np.argmax(y_test[0]))

"""
ì¶œë ¥ ì˜ˆì‹œ:
í™•ë¥ : [0.05, 0.02, 0.01, 0.8, 0.03, 0.01, 0.02, 0.01, 0.03, 0.02]
ì˜ˆì¸¡ í´ë˜ìŠ¤: 3
ì‹¤ì œ í´ë˜ìŠ¤: 3
"""
```

### ğŸ”µ Regression ì „ì²´ ì˜ˆì œ

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models

# 1. ë°ì´í„° ì¤€ë¹„ (ë‚˜ì´ ì˜ˆì¸¡ ì˜ˆì‹œ)
# ê°€ìƒ ë°ì´í„° ìƒì„±
np.random.seed(42)
n_samples = 1000

# ì´ë¯¸ì§€ ë°ì´í„° (64x64 RGB)
X_train = np.random.rand(n_samples, 64, 64, 3).astype('float32')

# ë‚˜ì´ ë ˆì´ë¸” (ì—°ì†ê°’)
y_train = np.random.uniform(18, 80, size=(n_samples, 1)).astype('float32')

print("í•™ìŠµ ë°ì´í„°:", X_train.shape)  # (1000, 64, 64, 3)
print("í•™ìŠµ ë ˆì´ë¸”:", y_train.shape)  # (1000, 1)
print("ë ˆì´ë¸” ìƒ˜í”Œ:", y_train[:5])    # [[32.5], [45.2], [28.1], ...]

# 2. Regression ëª¨ë¸ êµ¬ì¶•
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    
    # ì¶œë ¥ì¸µ: 1ê°œ ê°’ (ë‚˜ì´)
    layers.Dense(1, activation='linear')  # â† Linear
])

# 3. ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='mse',     # â† MSE
    metrics=['mae']  # MAE
)

# 4. í•™ìŠµ
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.2
)

# 5. ì˜ˆì¸¡
sample_image = X_train[0:1]
prediction = model.predict(sample_image)

print("\nì˜ˆì¸¡ ê²°ê³¼:")
print("ì˜ˆì¸¡ ë‚˜ì´:", prediction[0][0], "ì„¸")
print("ì‹¤ì œ ë‚˜ì´:", y_train[0][0], "ì„¸")
print("ì˜¤ì°¨:", abs(prediction[0][0] - y_train[0][0]), "ì„¸")

"""
ì¶œë ¥ ì˜ˆì‹œ:
ì˜ˆì¸¡ ë‚˜ì´: 32.8 ì„¸
ì‹¤ì œ ë‚˜ì´: 32.5 ì„¸
ì˜¤ì°¨: 0.3 ì„¸
"""
```

### ğŸŸ£ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ (Regression ì‘ìš©)

```python
# ì–¼êµ´ ëœë“œë§ˆí¬: ì—¬ëŸ¬ ê°œì˜ ì—°ì† ê°’ ì˜ˆì¸¡

# 1. ë°ì´í„° ì¤€ë¹„
n_samples = 1000
X_train = np.random.rand(n_samples, 128, 128, 3).astype('float32')

# 5ê°œ ëœë“œë§ˆí¬ì˜ (x, y) ì¢Œí‘œ = 10ê°œ ê°’
y_train = np.random.rand(n_samples, 10).astype('float32')
# [x1, y1, x2, y2, x3, y3, x4, y4, x5, y5]

print("í•™ìŠµ ë ˆì´ë¸”:", y_train.shape)  # (1000, 10)
print("ë ˆì´ë¸” ìƒ˜í”Œ:", y_train[0])     # [0.2, 0.3, 0.8, 0.3, ...]

# 2. ëª¨ë¸ êµ¬ì¶•
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    
    # ì¶œë ¥ì¸µ: 10ê°œ ê°’ (5ê°œ ì ì˜ x, y ì¢Œí‘œ)
    layers.Dense(10, activation='linear')  # â† 10ê°œ ì¶œë ¥
])

# 3. ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)

# 4. ì˜ˆì¸¡
prediction = model.predict(X_train[0:1])
print("\nì˜ˆì¸¡ ëœë“œë§ˆí¬:", prediction[0])
# [0.18, 0.32, 0.82, 0.28, 0.51, 0.49, ...]

# ì¢Œí‘œ ìŒìœ¼ë¡œ ë³€í™˜
landmarks = prediction[0].reshape(-1, 2)
print("ì¢Œí‘œ í˜•ì‹:")
for i, (x, y) in enumerate(landmarks):
    print(f"  ì  {i+1}: ({x:.2f}, {y:.2f})")
"""
ì¶œë ¥:
  ì  1: (0.18, 0.32)
  ì  2: (0.82, 0.28)
  ì  3: (0.51, 0.49)
  ì  4: (0.25, 0.75)
  ì  5: (0.78, 0.73)
"""
```

---

## ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ

### ğŸ¤” ì˜ì‚¬ê²°ì • í”Œë¡œìš°

```
ì§ˆë¬¸: "ì˜ˆì¸¡í•˜ë ¤ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ê°€?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "ì¹´í…Œê³ ë¦¬ì¸ê°€, ìˆ«ìì¸ê°€?"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                    â†“
ì¹´í…Œê³ ë¦¬              ì—°ì† ìˆ«ì
    â†“                    â†“
Classification      Regression
```

### âœ… Classificationì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°

```
1. ì¶œë ¥ì´ ì •í•´ì§„ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜
   âœ“ ë™ë¬¼ ì¢…ë¥˜ (ê°œ, ê³ ì–‘ì´, ìƒˆ)
   âœ“ ì§ˆë³‘ ìœ ë¬´ (ì •ìƒ, ì§ˆë³‘)
   âœ“ ê°ì • (í–‰ë³µ, ìŠ¬í””, í™”ë‚¨)

2. "ì´ê²ƒì€ ë¬´ì—‡ì¸ê°€?" ì§ˆë¬¸ì— ë‹µí•  ë•Œ
   âœ“ ì´ ì‚¬ì§„ì€ ê°œì¸ê°€, ê³ ì–‘ì´ì¸ê°€?
   âœ“ ì´ í™˜ìëŠ” ê±´ê°•í•œê°€, ì•„í”ˆê°€?
   âœ“ ì´ ì–¼êµ´ì€ ì›ƒëŠ”ê°€, ìš°ëŠ”ê°€?

3. í™•ë¥ ì´ í•„ìš”í•  ë•Œ
   âœ“ ê°œì¼ í™•ë¥ : 80%
   âœ“ ê³ ì–‘ì´ì¼ í™•ë¥ : 15%
   âœ“ ìƒˆì¼ í™•ë¥ : 5%
```

### âœ… Regressionì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°

```
1. ì¶œë ¥ì´ ì—°ì†ì ì¸ ìˆ«ì
   âœ“ ë‚˜ì´ (28.5ì„¸)
   âœ“ ê°€ê²© (3,500,000ì›)
   âœ“ ì¢Œí‘œ (x=120.5, y=85.3)

2. "ì´ê²ƒì€ ì–¼ë§ˆì¸ê°€?" ì§ˆë¬¸ì— ë‹µí•  ë•Œ
   âœ“ ì´ ì‚¬ëŒì€ ëª‡ ì‚´ì¸ê°€?
   âœ“ ì´ ì§‘ì€ ì–¼ë§ˆì¸ê°€?
   âœ“ ì´ ë¬¼ì²´ëŠ” ì–´ë””ì— ìˆëŠ”ê°€?

3. ì •ë°€í•œ ìˆ˜ì¹˜ê°€ í•„ìš”í•  ë•Œ
   âœ“ ì •í™•í•œ ìœ„ì¹˜
   âœ“ ì •í™•í•œ ì¸¡ì •ê°’
   âœ“ ì •í™•í•œ ì˜ˆì¸¡ê°’
```

### ğŸ”„ í˜¼í•© ì‚¬ìš© ì˜ˆì‹œ

```python
# ì˜ˆì‹œ: ì–¼êµ´ ë¶„ì„ ì‹œìŠ¤í…œ

# 1. Classification: ì„±ë³„ ë¶„ë¥˜
gender_model = build_classification_model(num_classes=2)
gender = gender_model.predict(face_image)
# ì¶œë ¥: [0.9, 0.1] â†’ ë‚¨ì„±

# 2. Regression: ë‚˜ì´ ì˜ˆì¸¡
age_model = build_regression_model(num_outputs=1)
age = age_model.predict(face_image)
# ì¶œë ¥: [28.5] â†’ 28.5ì„¸

# 3. Regression: ì–¼êµ´ ëœë“œë§ˆí¬
landmark_model = build_regression_model(num_outputs=10)
landmarks = landmark_model.predict(face_image)
# ì¶œë ¥: [120, 85, 200, 90, ...] â†’ ì¢Œí‘œë“¤
```

---

## í•µì‹¬ ìš”ì•½

### ğŸ¯ ê¸°ì–µí•´ì•¼ í•  5ê°€ì§€

```
1ï¸âƒ£ Classification = ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
   ì¶œë ¥: [ê°œ, ê³ ì–‘ì´, ìƒˆ] ì¤‘ í•˜ë‚˜
   í™œì„±í™”: Softmax
   ì†ì‹¤: Cross-Entropy

2ï¸âƒ£ Regression = ìˆ«ì ì˜ˆì¸¡
   ì¶œë ¥: ì—°ì†ì ì¸ ì‹¤ìˆ˜ ê°’
   í™œì„±í™”: Linear
   ì†ì‹¤: MSE/MAE

3ï¸âƒ£ Classification ì¶œë ¥ì€ í™•ë¥ 
   í•©ì´ 1.0 (100%)
   [0.8, 0.15, 0.05]

4ï¸âƒ£ Regression ì¶œë ¥ì€ ì‹¤ìˆ˜
   ì œì•½ ì—†ìŒ
   28.5, 120.3, -15.2

5ï¸âƒ£ ë¬¸ì œì— ë”°ë¼ ì„ íƒ
   "ë¬´ì—‡?" â†’ Classification
   "ì–¼ë§ˆ?" â†’ Regression
```

### ğŸ“Š í•œëˆˆì— ë³´ëŠ” ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      í•­ëª©          â”‚ Classification  â”‚   Regression    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì§ˆë¬¸              â”‚ "ë¬´ì—‡ì¸ê°€?"      â”‚ "ì–¼ë§ˆì¸ê°€?"      â”‚
â”‚ ì¶œë ¥              â”‚ ì¹´í…Œê³ ë¦¬         â”‚ ìˆ«ì             â”‚
â”‚ í™œì„±í™” í•¨ìˆ˜       â”‚ Softmax          â”‚ Linear           â”‚
â”‚ ì†ì‹¤ í•¨ìˆ˜         â”‚ Cross-Entropy    â”‚ MSE/MAE          â”‚
â”‚ ì¶œë ¥ ì˜ˆì‹œ         â”‚ [0.8, 0.15, 0.05]â”‚ 28.5             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ì´ì œ Classificationê³¼ Regressionì˜ ì°¨ì´ë¥¼ ì™„ë²½íˆ ì´í•´í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰
